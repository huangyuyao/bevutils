import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np

class PerspectiveTransformerLayer(nn.Module):

    def __init__(self, bv_size, pv_size, intrinsics, translate_z = 0.0, rotation_order='xyz', device='cuda:0', dtype=torch.float32):
        '''
        `translate_z` is a hyperparameter to be chose in range (-Inf, 1.0), the perspective view will be roughly scaled (1-translate_z) times.
        '''
        super(PerspectiveTransformerLayer, self).__init__()
        self.dtype = dtype
        self.dev = torch.device(device)
        self.rot_order = rotation_order
        self.bv_size, self.pv_size = bv_size, pv_size
        self.intrinsics = self._prepare_intrinsics(intrinsics)
        self.inv_intrinsics = torch.inverse(self.intrinsics)
        self.bv_pivot, self.pv_pivot = self._prepare_pivots(bv_size, pv_size, self.inv_intrinsics)
        self.n = torch.tensor([[0], [0], [1]], device=self.dev, dtype=self.dtype)
        self.tz = torch.tensor([translate_z], device=self.dev, dtype=self.dtype)
        self.bv_grid = self._prepare_coord_grid(*bv_size)

    def _prepare_intrinsics(self, intrinsics):
        if isinstance(intrinsics, list) or isinstance(intrinsics, np.array):
            intrinsics = torch.tensor(intrinsics, requires_grad=False, device=self.dev, dtype=self.dtype)
        assert isinstance(intrinsics, torch.Tensor)
        assert intrinsics.shape == (3, 3)
        return intrinsics
    
    def _prepare_pivots(self, bv_size, pv_size, inv_intrinsics):
        bv_pivot = torch.tensor([[bv_size[1]/2.0], [bv_size[0]], [1.0]], device=self.dev, dtype=self.dtype)
        pv_pivot = torch.tensor([[pv_size[1]/2.0], [pv_size[0]], [1.0]], device=self.dev, dtype=self.dtype)
        bv_pivot = inv_intrinsics @ bv_pivot
        pv_pivot = inv_intrinsics @ pv_pivot
        return bv_pivot, pv_pivot

    def _prepare_coord_grid(self, H, W):
        xgrid = torch.arange(W, requires_grad=False, device=self.dev, dtype=self.dtype).repeat(H, 1).view((H, W, 1, 1))
        ygrid = torch.arange(H, requires_grad=False, device=self.dev, dtype=self.dtype).unsqueeze_(1).repeat(1, W).view(H, W, 1, 1)
        grid = torch.cat((xgrid, ygrid, torch.ones_like(xgrid, device=self.dev, dtype=self.dtype)), dim=-2)
        return grid

    def forward(self, pv, rx, ry, rz):
        '''
        REFERENCES:
        - Homography: refers to https://en.wikipedia.org/wiki/Homography_(computer_vision)
        - Bilinear Interpolation: refers to https://medium.com/@shanlins/spatial-transformer-networks-stn-and-its-implementation-2638d58d41f8
        '''
        B, C, Hp, Wp, Hb, Wb = *pv.shape, *self.bv_size
        assert B == rx.shape[0]
        # get constrained translation vector `t`, code auto-generated by docs/yield_constrained_t.m
        R = self._make_rot_mat(rx, ry, rz)
        n = torch.bmm(torch.inverse(R), self.n.expand(B, 3, 1))
        b, p, t2 = self.bv_pivot, self.pv_pivot, self.tz.expand(B)
        t0 = (R[:,0,2] - b[0]*R[:,2,2] + p[0]*R[:,0,0] + p[1]*R[:,0,1] + b[0]*n[:,2,0]*t2 - b[0]*p[0]*R[:,2,0] - b[0]*p[1]*R[:,2,1] + b[0]*n[:,0,0]*p[0]*t2 + b[0]*n[:,1,0]*p[1]*t2)/(n[:,2,0] + n[:,0,0]*p[0] + n[:,1,0]*p[1])
        t1 = (R[:,1,2] - b[1]*R[:,2,2] + p[0]*R[:,1,0] + p[1]*R[:,1,1] + b[1]*n[:,2,0]*t2 - b[1]*p[0]*R[:,2,0] - b[1]*p[1]*R[:,2,1] + b[1]*n[:,0,0]*p[0]*t2 + b[1]*n[:,1,0]*p[1]*t2)/(n[:,2,0] + n[:,0,0]*p[0] + n[:,1,0]*p[1])
        t = torch.cat((t0[:, None, None], t1[:, None, None], t2[:, None, None]), dim=1)
        # get coordinates on perspective view for each grid: `pv_coord` with shape (B, Hb, Wb, 2, 1)
        bv_grid = self.bv_grid.expand(B, Hb, Wb, 3, 1)
        H = self.intrinsics @ torch.inverse(R - t @ n.transpose(1, 2)) @ self.inv_intrinsics
        pv_coord = torch.matmul(H[:, None, None, :, :], bv_grid)
        pv_coord[:, :, :, 0:2, :] /= pv_coord[:, :, :, 2:3, :]
        # gather pixels acoording to `pv_coord`
        x = pv_coord[:,None,:,:,0,0] # with shape (B, 1, Hb, Wb)
        y = pv_coord[:,None,:,:,1,0]
        x0 = x.to(torch.long).clamp_(0, Wp-2)
        y0 = y.to(torch.long).clamp_(0, Hp-2)
        offset_00 = y0 * Wp + x0
        offset_01 = offset_00 + 1
        offset_10 = offset_00 + Wp
        offset_11 = offset_10 + 1
        pv = pv.view(B, C, Hp*Wp) # with shape (B, C, Hp*Wp)
        pvmap = [
            torch.gather(pv, -1, offset_00.expand(B, C, Hb, Wb).view(B, C, Hb*Wb)),
            torch.gather(pv, -1, offset_01.expand(B, C, Hb, Wb).view(B, C, Hb*Wb)),
            torch.gather(pv, -1, offset_10.expand(B, C, Hb, Wb).view(B, C, Hb*Wb)),
            torch.gather(pv, -1, offset_11.expand(B, C, Hb, Wb).view(B, C, Hb*Wb))] # pv maps: with shape (B, C, Hb*Wb)
        # combine pv pixels
        x0, x1, y0, y1 = (x - x0.to(self.dtype)), ((x0+1).to(self.dtype) - x), (y - y0.to(self.dtype)), ((y0+1).to(self.dtype) - y)
        weights = [(x0 * y0), (x0 * y1), (x1 * y0), (x1 * y1)] # weight : with shape (B, 1, Hb, Wb)
        bvmap = sum([w.expand(B, C, Hb, Wb) * p.view(B, C, Hb, Wb) for w, p in zip(weights, pvmap)]) # bvmap with shape (B, C, Hb, Wb)
        mask = (~((x >= 0) & (x < Wp) & (y >= 0) & (y < Hp))).expand(B, C, Hb, Wb)
        bvmap[mask] = 0.0
        return bvmap

    def _make_rot_mat(self, rx, ry, rz):
        cx, cy, cz = torch.cos(rx), torch.cos(ry), torch.cos(rz)
        sx, sy, sz = torch.sin(rx), torch.sin(ry), torch.sin(rz)
        B = rx.shape[0]
        _Rx = torch.tensor([[1.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0, 0.0]], device=self.dev, dtype=self.dtype).repeat(B, 1, 1)
        _Rx[:, 1, 1], _Rx[:, 1, 2], _Rx[:, 2, 1], _Rx[:, 2, 2] = cx, -sx, sx, cx
        _Ry = torch.tensor([[0.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.0, 0.0, 0.0]], device=self.dev, dtype=self.dtype).repeat(B, 1, 1)
        _Ry[:, 0, 0], _Ry[:, 0, 2], _Ry[:, 2, 0], _Ry[:, 2, 2] = cy, -sy, sy, cy
        _Rz = torch.tensor([[0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0, 1.0]], device=self.dev, dtype=self.dtype).repeat(B, 1, 1)
        _Rz[:, 0, 0], _Rz[:, 0, 1], _Rz[:, 1, 0], _Rz[:, 1, 1] = cz, -sz, sz, cz
        _R = {'x' : _Rx, 'y' : _Ry, 'z' : _Rz}
        R = torch.eye(3, device=self.dev, dtype=self.dtype).repeat(B, 1, 1)
        for i in self.rot_order:
            R = torch.bmm(R, _R[i])
        return R